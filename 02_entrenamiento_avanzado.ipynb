{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8fc865",
   "metadata": {},
   "source": [
    "# 02. Entrenamiento Avanzado (The Brain)\n",
    "\n",
    "Este notebook entrena, optimiza y ensambla los modelos predictivos.\n",
    "\n",
    "**Fases:**\n",
    "1. **Preparaci√≥n de Targets**: Convertir 'H', 'D', 'A' a num√©rico.\n",
    "2. **Torneo de Modelos**: Comparativa inicial (XGB vs RF vs LR).\n",
    "3. **Optimizaci√≥n Extrema**: GridSearchCV con TimeSeriesSplit.\n",
    "4. **Stacking Ensemble**: Creaci√≥n del Super-Modelo.\n",
    "5. **Persistencia**: Guardado del modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdc8ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config\n",
    "INPUT_FILE = 'df_final_features.csv'\n",
    "MODEL_FILE = 'modelo_city_group.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce95b03",
   "metadata": {},
   "source": [
    "## 1. Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d36c6aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Target: {'A': 0, 'D': 1, 'H': 2}\n",
      "Entrenando con 18 variables: ['Home_Elo', 'Away_Elo', 'Home_Att_Strength', 'Away_Att_Strength', 'Home_Def_Weakness', 'Away_Def_Weakness', 'Home_FIFA_Ova', 'Away_FIFA_Ova', 'Home_Market_Value', 'Away_Market_Value', 'Home_Rest_Days', 'Away_Rest_Days', 'Home_xG_Proxy', 'Away_xG_Proxy', 'Home_Dominance', 'Away_Dominance', 'Home_Pressure', 'Away_Pressure']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Encoding Target\n",
    "le = LabelEncoder()\n",
    "df['Target'] = le.fit_transform(df['FTR']) # A=0, D=1, H=2 (Verificar orden)\n",
    "print(\"Mapping Target:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# Definir Features X\n",
    "exclude = ['Date', 'Season', 'HomeTeam', 'AwayTeam', 'FTR', 'FTHG', 'FTAG', 'Target', 'B365H', 'B365D', 'B365A']\n",
    "features = [c for c in df.columns if c not in exclude]\n",
    "print(f\"Entrenando con {len(features)} variables: {features}\")\n",
    "\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Split Temporal (Respetar orden cronologico es CRITICO)\n",
    "# Usaremos ultimos 20% para test final (\"Out of Time\")\n",
    "split_idx = int(len(df) * 0.80)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Scaling (Importante para Regresion Logistica)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42b3bc",
   "metadata": {},
   "source": [
    "## 2. Torneo de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49fdc997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Log Loss: 0.8991 (+/- 0.0252)\n",
      "RandomForest Log Loss: 0.9321 (+/- 0.0265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Log Loss: 0.9103 (+/- 0.0208)\n",
      "\n",
      "üèÜ Ganador Fase Previa: LogReg\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'LogReg': LogisticRegression(max_iter=1000, C=0.1),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, max_depth=3, learning_rate=0.05)\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Usar datos escalados para todos por simplicidad aqui, aunque arboles no lo necesitan\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='neg_log_loss')\n",
    "    results[name] = -scores.mean()\n",
    "    print(f\"{name} Log Loss: {-scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"\\nüèÜ Ganador Fase Previa: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5be5e",
   "metadata": {},
   "source": [
    "## 3. Ensemble Stacking (El Super-Modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03c552fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Voting Ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\emili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTADOS FINALES TEST SET:\n",
      "Log Loss: 0.9181\n",
      "Accuracy: 0.5702\n"
     ]
    }
   ],
   "source": [
    "# Creamos un VotingClassifier con los 3 modelos (Soft Voting)\n",
    "# VotingClassifier SI es compatible con TimeSeriesSplit indirectamente al usarse dentro de CalibratedClassifierCV\n",
    "# o simplemente como estimador robusto.\n",
    "estimators = [\n",
    "    ('lr', models['LogReg']),\n",
    "    ('rf', models['RandomForest']),\n",
    "    ('xgb', models['XGBoost'])\n",
    "]\n",
    "\n",
    "# Usamos VotingClassifier en lugar de Stacking para evitar problemas de particion con TimeSeriesSplit\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"Entrenando Voting Ensemble...\")\n",
    "# Para VotingClassifier, fit entrena los estimadores base\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calibraci√≥n de Probabilidades (Isotonic)\n",
    "# Crucial para apuestas: asegurar que 60% prob signifique 60% veces gana\n",
    "calibrated_clf = CalibratedClassifierCV(voting_clf, method='isotonic', cv=tscv)\n",
    "calibrated_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluacion Final\n",
    "y_prob = calibrated_clf.predict_proba(X_test_scaled)\n",
    "loss = log_loss(y_test, y_prob)\n",
    "acc = accuracy_score(y_test, calibrated_clf.predict(X_test_scaled))\n",
    "\n",
    "print(f\"\\nRESULTADOS FINALES TEST SET:\")\n",
    "print(f\"Log Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d85930",
   "metadata": {},
   "source": [
    "## 4. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1c49c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo guardado en modelo_city_group.joblib\n"
     ]
    }
   ],
   "source": [
    "# Guardamos Modelo + Scaler + Encoder en un diccionario para la App\n",
    "artifact = {\n",
    "    'model': calibrated_clf,\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': le,\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "joblib.dump(artifact, MODEL_FILE)\n",
    "print(f\"‚úÖ Modelo guardado en {MODEL_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6a46b-c60b-43fc-8337-8a4ab20897eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b10686-279f-44ad-b69a-ce1d4f0a6e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397e65a-449c-40f4-9006-1b36a8fdcdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d691758-074a-4cce-8f10-fc4e611098a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a39f30-8f7f-4b93-974e-64d7d0a0b411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7cfc0-bca8-4a1f-9b49-b0d5e6d7244a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
