{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75de2068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\emili\\miniconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\emili\\miniconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\emili\\miniconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: optuna in c:\\users\\emili\\miniconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emili\\miniconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\emili\\miniconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\emili\\miniconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\emili\\miniconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\emili\\miniconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\emili\\miniconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\emili\\miniconda3\\lib\\site-packages (6.5.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\emili\\miniconda3\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from optuna) (2.0.45)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from optuna) (1.18.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\emili\\miniconda3\\lib\\site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\emili\\miniconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\emili\\miniconda3\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: six in c:\\users\\emili\\miniconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\emili\\miniconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from plotly) (2.15.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipywidgets) (8.13.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: tomli in c:\\users\\emili\\miniconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (2.4.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\emili\\miniconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\emili\\miniconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\emili\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\emili\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn optuna matplotlib seaborn xgboost lightgbm catboost tqdm plotly ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc330298",
   "metadata": {},
   "source": [
    "# 01. IngenierÃ­a de Datos (City Football Group Engine)\n",
    "\n",
    "Este notebook es el motor del proyecto. Su misiÃ³n es transformar datos crudos en KPIs profesionales.\n",
    "\n",
    "**Fases:**\n",
    "1. **Carga Viva**: Descarga de datos en tiempo real de la temporada actual.\n",
    "2. **Limpieza y UnificaciÃ³n**: Cruce de datos de partidos con Valor de Mercado (Transfermarkt) y FIFA (SoFIFA).\n",
    "3. **The City Engine**: GeneraciÃ³n de mÃ©tricas avanzadas (xG Proxy, PresiÃ³n, Dominio).\n",
    "4. **Rating Engines**: CÃ¡lculo de Elo, Glicko-2 y Dixon-Coles partido a partido.\n",
    "5. **ExportaciÃ³n**: `df_final_features.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6024178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ df_raw not found in locals. Attempting to reload data inside Engine block...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Temp\\ipykernel_32124\\566427362.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_raw['Date'] = pd.to_datetime(df_raw['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Data reloaded inside engine: 5700 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- PRO FEATURE ENGINE (ACADEMIC v2.0) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# DATA LOADING FALLBACK (Redundant Safety)\n",
    "# Check if df_raw is available, if not, try to reconstruct it from previous steps logic\n",
    "if 'df_raw' not in locals():\n",
    "    print(\"âš ï¸ df_raw not found in locals. Attempting to reload data inside Engine block...\")\n",
    "    DATA_DIR = 'data'\n",
    "    OUTPUT_FILE = 'df_final_features.csv'\n",
    "    CURRENT_SEASON_URL = 'https://www.football-data.co.uk/mmz4281/2425/SP1.csv'\n",
    "    dfs = []\n",
    "    # Simplified loading for fallback\n",
    "    # Assuming standard structure 2010-2025\n",
    "    for year in range(10, 26):\n",
    "        s_str = f\"{year:02d}{(year+1)%100:02d}\"\n",
    "        filename = f\"SP1_{s_str}.csv\"\n",
    "        path = os.path.join(DATA_DIR, filename)\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                dt = pd.read_csv(path, encoding='latin1', on_bad_lines='skip')\n",
    "                dt['Season'] = 2000 + year\n",
    "                dfs.append(dt)\n",
    "            except: pass\n",
    "    if dfs:\n",
    "        df_raw = pd.concat(dfs, ignore_index=True)\n",
    "        df_raw['Date'] = pd.to_datetime(df_raw['Date'], dayfirst=True, errors='coerce')\n",
    "        df_raw = df_raw.sort_values('Date').reset_index(drop=True)\n",
    "        # Apply mapping\n",
    "        team_map = {\n",
    "            'Ath Bilbao': 'Athletic Club', 'Atletico Madrid': 'AtlÃ©tico Madrid',\n",
    "            'Espanol': 'RCD Espanyol', 'Real Madrid': 'Real Madrid',\n",
    "            'Barcelona': 'FC Barcelona', 'Valencia': 'Valencia CF',\n",
    "            'Sevilla': 'Sevilla FC', 'Betis': 'Real Betis BalompiÃ©'\n",
    "        }\n",
    "        # Simplified map for safety\n",
    "        df_raw['HomeTeam'] = df_raw['HomeTeam'].replace(team_map)\n",
    "        df_raw['AwayTeam'] = df_raw['AwayTeam'].replace(team_map)\n",
    "        print(f\"ðŸ”„ Data reloaded inside engine: {len(df_raw)} rows\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not load data for ProFeatureEngine\")\n",
    "\n",
    "class ProFeatureEngine:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df['Date'] = pd.to_datetime(self.df['Date'], dayfirst=True)\n",
    "        self.df = self.df.sort_values(['Date'])\n",
    "        \n",
    "    def _calculate_base_metrics(self):\n",
    "        self.df['Home_Points'] = np.where(self.df['FTR'] == 'H', 3, np.where(self.df['FTR'] == 'D', 1, 0))\n",
    "        self.df['Away_Points'] = np.where(self.df['FTR'] == 'A', 3, np.where(self.df['FTR'] == 'D', 1, 0))\n",
    "        self.df['Home_xG_Raw'] = (self.df['HS'] * 0.09) + (self.df['HST'] * 0.29)\n",
    "        self.df['Away_xG_Raw'] = (self.df['AS'] * 0.09) + (self.df['AST'] * 0.29)\n",
    "        self.df['Home_Possession_Est'] = 0.50 \n",
    "        self.df['Away_Possession_Est'] = 0.50\n",
    "        self.df['Home_Pressure_Raw'] = (self.df['HF'] + self.df['HY'] + self.df['HR']) / np.maximum(self.df['Away_Possession_Est'], 0.1)\n",
    "        self.df['Away_Pressure_Raw'] = (self.df['AF'] + self.df['AY'] + self.df['AR']) / np.maximum(self.df['Home_Possession_Est'], 0.1)\n",
    "        \n",
    "    def _rolling_features(self, window=5):\n",
    "        cols_needed = ['Date', 'Season', 'HomeTeam', 'AwayTeam', \n",
    "                       'Home_xG_Raw', 'Away_xG_Raw', \n",
    "                       'Home_Points', 'Away_Points',\n",
    "                       'Home_Pressure_Raw', 'Away_Pressure_Raw']\n",
    "        df_lite = self.df[cols_needed].copy()\n",
    "        \n",
    "        home_side = df_lite[['Date', 'HomeTeam', 'Home_xG_Raw', 'Home_Points', 'Home_Pressure_Raw']].rename(\n",
    "            columns={'HomeTeam': 'Team', 'Home_xG_Raw': 'xG', 'Home_Points': 'Pts', 'Home_Pressure_Raw': 'Press'}\n",
    "        )\n",
    "        away_side = df_lite[['Date', 'AwayTeam', 'Away_xG_Raw', 'Away_Points', 'Away_Pressure_Raw']].rename(\n",
    "            columns={'AwayTeam': 'Team', 'Away_xG_Raw': 'xG', 'Away_Points': 'Pts', 'Away_Pressure_Raw': 'Press'}\n",
    "        )\n",
    "        \n",
    "        all_matches = pd.concat([home_side, away_side]).sort_values('Date')\n",
    "        \n",
    "        # GroupBy + Shift(1) + Rolling\n",
    "        grouped = all_matches.groupby('Team')\n",
    "        \n",
    "        all_matches['xG_Avg_L5'] = grouped['xG'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).mean())\n",
    "        all_matches['Streak_L5'] = grouped['Pts'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).sum())\n",
    "        all_matches['Pressure_Avg_L5'] = grouped['Press'].transform(lambda x: x.shift(1).rolling(window, min_periods=1).mean())\n",
    "        \n",
    "        # Merge back\n",
    "        self.df = self.df.merge(\n",
    "            all_matches[['Date', 'Team', 'xG_Avg_L5', 'Streak_L5', 'Pressure_Avg_L5']],\n",
    "            left_on=['Date', 'HomeTeam'], right_on=['Date', 'Team'], how='left'\n",
    "        ).rename(columns={'xG_Avg_L5': 'Home_xG_Avg_L5', 'Streak_L5': 'Home_Streak_L5', 'Pressure_Avg_L5': 'Home_Pressure_Avg_L5'}).drop(columns=['Team'])\n",
    "        \n",
    "        self.df = self.df.merge(\n",
    "            all_matches[['Date', 'Team', 'xG_Avg_L5', 'Streak_L5', 'Pressure_Avg_L5']],\n",
    "            left_on=['Date', 'AwayTeam'], right_on=['Date', 'Team'], how='left'\n",
    "        ).rename(columns={'xG_Avg_L5': 'Away_xG_Avg_L5', 'Streak_L5': 'Away_Streak_L5', 'Pressure_Avg_L5': 'Away_Pressure_Avg_L5'}).drop(columns=['Team'])\n",
    "        \n",
    "    def _h2h_features(self, window=3):\n",
    "        h2h_home = []\n",
    "        h2h_away = []\n",
    "        history = {} \n",
    "        for idx, row in self.df.iterrows():\n",
    "            h, a = row['HomeTeam'], row['AwayTeam']\n",
    "            h_pts = row['Home_Points']\n",
    "            a_pts = row['Away_Points']\n",
    "            pair = tuple(sorted([h, a]))\n",
    "            if pair not in history: history[pair] = []\n",
    "                \n",
    "            past_games = history[pair]\n",
    "            if len(past_games) == 0:\n",
    "                h2h_home.append(1.5) \n",
    "                h2h_away.append(1.5)\n",
    "            else:\n",
    "                relevant_pts = []\n",
    "                for game_h, game_pts_h, game_pts_a in past_games[-window:]:\n",
    "                    if game_h == h: relevant_pts.append(game_pts_h)\n",
    "                    else: relevant_pts.append(game_pts_a)\n",
    "                h2h_home.append(np.mean(relevant_pts))\n",
    "                \n",
    "                relevant_pts_a = []\n",
    "                for game_h, game_pts_h, game_pts_a in past_games[-window:]:\n",
    "                    if game_h == a: relevant_pts_a.append(game_pts_h)\n",
    "                    else: relevant_pts_a.append(game_pts_a)\n",
    "                h2h_away.append(np.mean(relevant_pts_a))\n",
    "\n",
    "            history[pair].append((h, h_pts, a_pts))\n",
    "            \n",
    "        self.df['Home_H2H_L3'] = h2h_home\n",
    "        self.df['Away_H2H_L3'] = h2h_away\n",
    "\n",
    "    def run(self):\n",
    "        self._calculate_base_metrics()\n",
    "        self._rolling_features()\n",
    "        self._h2h_features()\n",
    "        return self.df.fillna(0)\n",
    "\n",
    "engine = ProFeatureEngine(df_raw)\n",
    "df = engine.run()\n",
    "\n",
    "home_fifa_ovas = []\n",
    "away_fifa_ovas = []\n",
    "home_market_vals = []\n",
    "away_market_vals = []\n",
    "\n",
    "# Try to use existing get_team_metadata or fallback\n",
    "def get_meta_safe(team, season, data, def_val, key):\n",
    "    try: return get_team_metadata(team, season, data, def_val, key)\n",
    "    except: return def_val\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    s = row['Season']\n",
    "    # If sofifa_data/tm_data not strictly defined in this cell scope, we hope it's global.\n",
    "    # If not, we fill defaults.\n",
    "    try:\n",
    "        h_ova = get_team_metadata(row['HomeTeam'], s, sofifa_data, 75, 'ova')\n",
    "        a_ova = get_team_metadata(row['AwayTeam'], s, sofifa_data, 75, 'ova')\n",
    "        h_val = get_team_metadata(row['HomeTeam'], s, tm_data, 10.0, 'market')\n",
    "        a_val = get_team_metadata(row['AwayTeam'], s, tm_data, 10.0, 'market')\n",
    "    except:\n",
    "        h_ova, a_ova, h_val, a_val = 75, 75, 10.0, 10.0\n",
    "        \n",
    "    home_fifa_ovas.append(h_ova)\n",
    "    away_fifa_ovas.append(a_ova)\n",
    "    home_market_vals.append(h_val)\n",
    "    away_market_vals.append(a_val)\n",
    "\n",
    "df['Home_FIFA_Ova'] = home_fifa_ovas\n",
    "df['Away_FIFA_Ova'] = away_fifa_ovas\n",
    "df['Home_Market_Value'] = home_market_vals\n",
    "df['Away_Market_Value'] = away_market_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28aef7",
   "metadata": {},
   "source": [
    "## 1. FunciÃ³n `fetch_live_data` (SincronizaciÃ³n Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2442edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Intentando descargar datos en vivo de: https://www.football-data.co.uk/mmz4281/2425/SP1.csv...\n",
      "âŒ ExcepciÃ³n al descargar: name 'requests' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_live_data():\n",
    "    \"\"\"\n",
    "    Descarga el CSV de la temporada actual y lo guarda localmente.\n",
    "    Si falla, usa el archivo local existente.\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”„ Intentando descargar datos en vivo de: {CURRENT_SEASON_URL}...\")\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        r = requests.get(CURRENT_SEASON_URL, headers=headers, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            # Guardar como SP1_2425.csv (asumiendo temporada actual)\n",
    "            # Nota: Ajustar el nombre del archivo segÃºn la temporada si es necesario automÃ¡gicamente\n",
    "            with open(os.path.join(DATA_DIR, 'SP1_2425.csv'), 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            print(\"âœ… Datos descargados y actualizados correctamente.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âš ï¸ Error al descargar: Status {r.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ExcepciÃ³n al descargar: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ejecutar sincronizaciÃ³n al inicio\n",
    "fetch_live_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f257da",
   "metadata": {},
   "source": [
    "## 2. Carga y UnificaciÃ³n de Datos HistÃ³ricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c12c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partidos cargados: 5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\AppData\\Local\\Temp\\ipykernel_32124\\1993894176.py:28: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_raw['Date'] = pd.to_datetime(df_raw['Date'], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Cargar archivos JSON auxiliares\n",
    "with open(os.path.join(DATA_DIR, 'sofifa_history.json'), 'r', encoding='utf-8') as f:\n",
    "    sofifa_data = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'transfermarkt_history.json'), 'r', encoding='utf-8') as f:\n",
    "    tm_data = json.load(f)\n",
    "\n",
    "# Lista de temporadas a cargar (ajustar rango segÃºn disponibilidad real)\n",
    "# Ejemplo: 2010 a 2025\n",
    "seasons = []\n",
    "dfs = []\n",
    "\n",
    "for year in range(10, 26): # 10-11 a 24-25\n",
    "    s_str = f\"{year:02d}{(year+1)%100:02d}\"\n",
    "    filename = f\"SP1_{s_str}.csv\"\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df_temp = pd.read_csv(path, encoding='latin1', on_bad_lines='skip') # 'encoding' suele ser necesario para football-data\n",
    "            df_temp['Season'] = 2000 + year\n",
    "            dfs.append(df_temp)\n",
    "            seasons.append(2000 + year)\n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {filename}: {e}\")\n",
    "\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "df_raw['Date'] = pd.to_datetime(df_raw['Date'], dayfirst=True, errors='coerce')\n",
    "df_raw = df_raw.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Total partidos cargados: {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e42df",
   "metadata": {},
   "source": [
    "### NormalizaciÃ³n de Nombres de Equipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5cbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa manual para casos difÃ­ciles, el resto usarÃ¡ fuzzy match o directo\n",
    "team_map = {\n",
    "    'Ath Bilbao': 'Athletic Club',\n",
    "    'Atletico Madrid': 'AtlÃ©tico Madrid',\n",
    "    'Espanol': 'RCD Espanyol',\n",
    "    'Sp Gijon': 'Sporting GijÃ³n',\n",
    "    'Real Madrid': 'Real Madrid',\n",
    "    'Barcelona': 'FC Barcelona',\n",
    "    'Valencia': 'Valencia CF',\n",
    "    'Sevilla': 'Sevilla FC',\n",
    "    'Betis': 'Real Betis BalompiÃ©',\n",
    "    'Sociedad': 'Real Sociedad',\n",
    "    'La Coruna': 'Deportivo de La CoruÃ±a',\n",
    "    'Celta': 'RC Celta de Vigo',\n",
    "    'Villarreal': 'Villarreal CF',\n",
    "    'Mallorca': 'RCD Mallorca',\n",
    "    'Osasuna': 'CA Osasuna',\n",
    "    'Alaves': 'Deportivo AlavÃ©s',\n",
    "    'Vallecano': 'Rayo Vallecano',\n",
    "    'Getafe': 'Getafe CF',\n",
    "    'Levante': 'Levante UD',\n",
    "    'Girona': 'Girona FC',\n",
    "    'Las Palmas': 'UD Las Palmas',\n",
    "    'Leganes': 'CD LeganÃ©s',\n",
    "    'Almeria': 'UD AlmerÃ­a',\n",
    "    'Granada': 'Granada CF',\n",
    "    'Elche': 'Elche CF',\n",
    "    'Valladolid': 'Real Valladolid CF',\n",
    "    'Eibar': 'SD Eibar',\n",
    "    'Huesca': 'SD Huesca',\n",
    "    'Cadiz': 'CÃ¡diz CF',\n",
    "    'Sp Gijon': 'Sporting de GijÃ³n'\n",
    "}\n",
    "\n",
    "def standardize_team(name):\n",
    "    return team_map.get(name, name)\n",
    "\n",
    "df_raw['HomeTeam'] = df_raw['HomeTeam'].apply(standardize_team)\n",
    "df_raw['AwayTeam'] = df_raw['AwayTeam'].apply(standardize_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4a49",
   "metadata": {},
   "source": [
    "## 3. Generador de Proxies (\"The City Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dba6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones Auxiliares para Datos Externos\n",
    "def get_team_metadata(team_name, season_year, source_data, default_val=None, value_key='value'):\n",
    "    year_str = str(season_year)\n",
    "    if year_str not in source_data:\n",
    "        return default_val\n",
    "    \n",
    "    candidates = source_data[year_str]\n",
    "    # Buscar coincidencia exacta o cercana\n",
    "    # Optimizacion rapida: buscar substring\n",
    "    for item in candidates:\n",
    "        t = item['team']\n",
    "        if team_name in t or t in team_name:\n",
    "            if value_key == 'ova':\n",
    "                return int(item['ova'])\n",
    "            elif value_key == 'market':\n",
    "                # Limpiar valor \"â‚¬100m\" -> 100\n",
    "                val_str = item.get('value', '0')\n",
    "                val_clean = val_str.replace('â‚¬', '').replace('m', '').replace('Th', '/1000').strip()\n",
    "                \n",
    "                # FIX: Handle Billions (bn)\n",
    "                if 'bn' in val_clean:\n",
    "                    try:\n",
    "                        return float(val_clean.replace('bn', '')) * 1000\n",
    "                    except:\n",
    "                        return default_val\n",
    "                        \n",
    "                try:\n",
    "                    if '/1000' in val_clean:\n",
    "                        return float(val_clean.replace('/1000', '')) / 1000\n",
    "                    return float(val_clean)\n",
    "                except:\n",
    "                    return default_val\n",
    "    return default_val\n",
    "\n",
    "# Feature Engineering Vectorizado\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 1. Proxy xG (Expected Goals)\n",
    "# Formula: (Tiros * 0.09) + (TirosPuerta * 0.29)\n",
    "# Usando HS (Home Shots) y HST (Home Shots on Target)\n",
    "df['Home_xG_Proxy'] = (df['HS'] * 0.09) + (df['HST'] * 0.29)\n",
    "df['Away_xG_Proxy'] = (df['AS'] * 0.09) + (df['AST'] * 0.29)\n",
    "\n",
    "# 2. Proxy Presion\n",
    "# Posesion no siempre esta disponible en footbal-data antigua (antes de 2018 aprox)\n",
    "# Si falta, estimamos posesion basada en cuotas (equipos favoritos suelen tener mas posesion)\n",
    "# Estimacion simple: 50% si no hay dato\n",
    "df['Home_Possession_Est'] = 0.50 # Placeholder si no tenemos dato real\n",
    "df['Away_Possession_Est'] = 0.50\n",
    "\n",
    "df['Home_Pressure'] = (df['HF'] + df['HY'] + df['HR']) / df['Away_Possession_Est'] # Faltas del local sobre posesion rival\n",
    "df['Away_Pressure'] = (df['AF'] + df['AY'] + df['AR']) / df['Home_Possession_Est']\n",
    "\n",
    "# 3. Proxy Dominio\n",
    "# % Corners en campo rival\n",
    "total_corners = df['HC'] + df['AC']\n",
    "df['Home_Dominance'] = np.where(total_corners > 0, df['HC'] / total_corners, 0.5)\n",
    "df['Away_Dominance'] = np.where(total_corners > 0, df['AC'] / total_corners, 0.5)\n",
    "\n",
    "# 4. Fatiga Real\n",
    "# Dias desde el ultimo partido\n",
    "df['Home_Rest_Days'] = 7.0 # Default\n",
    "df['Away_Rest_Days'] = 7.0\n",
    "\n",
    "last_date = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    date = row['Date']\n",
    "    home = row['HomeTeam']\n",
    "    away = row['AwayTeam']\n",
    "    \n",
    "    if home in last_date:\n",
    "        delta = (date - last_date[home]).days\n",
    "        df.at[idx, 'Home_Rest_Days'] = min(delta, 30) # Cap en 30 dias\n",
    "    \n",
    "    if away in last_date:\n",
    "        delta = (date - last_date[away]).days\n",
    "        df.at[idx, 'Away_Rest_Days'] = min(delta, 30)\n",
    "        \n",
    "    last_date[home] = date\n",
    "    last_date[away] = date\n",
    "\n",
    "# 5. Enriquecimiento con FIFA y Valor de Mercado\n",
    "# Esto lo haremos fila a fila porque depende del aÃ±o de la temporada\n",
    "home_fifa_ovas = []\n",
    "away_fifa_ovas = []\n",
    "home_market_vals = []\n",
    "away_market_vals = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    season = row['Season']\n",
    "    h_ova = get_team_metadata(row['HomeTeam'], season, sofifa_data, default_val=75, value_key='ova')\n",
    "    a_ova = get_team_metadata(row['AwayTeam'], season, sofifa_data, default_val=75, value_key='ova')\n",
    "    h_val = get_team_metadata(row['HomeTeam'], season, tm_data, default_val=10.0, value_key='market')\n",
    "    a_val = get_team_metadata(row['AwayTeam'], season, tm_data, default_val=10.0, value_key='market')\n",
    "    \n",
    "    home_fifa_ovas.append(h_ova)\n",
    "    away_fifa_ovas.append(a_ova)\n",
    "    home_market_vals.append(h_val)\n",
    "    away_market_vals.append(a_val)\n",
    "\n",
    "df['Home_FIFA_Ova'] = home_fifa_ovas\n",
    "df['Away_FIFA_Ova'] = away_fifa_ovas\n",
    "df['Home_Market_Value'] = home_market_vals\n",
    "df['Away_Market_Value'] = away_market_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00999723",
   "metadata": {},
   "source": [
    "## 4. Rating Engines (Elo, Glicko-2, Dixon-Coles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c234537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementacion Vectorizada/Iterativa de Elo\n",
    "# Para Dixon-Coles y Glicko simplificados usaremos versiones iterativas rapidas\n",
    "\n",
    "elo_ratings = {team: 1500 for team in df['HomeTeam'].unique()}\n",
    "elo_k = 20\n",
    "\n",
    "defense_ratings = {team: 1.0 for team in df['HomeTeam'].unique()}\n",
    "attack_ratings = {team: 1.0 for team in df['HomeTeam'].unique()}\n",
    "\n",
    "home_elo_series = []\n",
    "away_elo_series = []\n",
    "home_att_series = []\n",
    "away_att_series = []\n",
    "home_def_series = []\n",
    "away_def_series = []\n",
    "\n",
    "def get_result_score(ftr):\n",
    "    if ftr == 'H': return 1.0\n",
    "    if ftr == 'D': return 0.5\n",
    "    return 0.0\n",
    "\n",
    "# Parametros Dixon Coles Simple (Actualizacion progresiva)\n",
    "dc_lr = 0.01 # Learning rate\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    h_team = row['HomeTeam']\n",
    "    a_team = row['AwayTeam']\n",
    "    \n",
    "    # --- Antes del partido: Guardar Ratings ---\n",
    "    h_elo = elo_ratings.get(h_team, 1500)\n",
    "    a_elo = elo_ratings.get(a_team, 1500)\n",
    "    \n",
    "    h_att = attack_ratings.get(h_team, 1.0)\n",
    "    h_def = defense_ratings.get(h_team, 1.0)\n",
    "    a_att = attack_ratings.get(a_team, 1.0)\n",
    "    a_def = defense_ratings.get(a_team, 1.0)\n",
    "    \n",
    "    home_elo_series.append(h_elo)\n",
    "    away_elo_series.append(a_elo)\n",
    "    home_att_series.append(h_att)\n",
    "    away_att_series.append(a_att)\n",
    "    home_def_series.append(h_def)\n",
    "    away_def_series.append(a_def)\n",
    "\n",
    "    # --- Actualizacion Elo ---\n",
    "    # HGA: Home Ground Advantage (aprox 70 puntos)\n",
    "    dr = a_elo - (h_elo + 70)\n",
    "    e_prob = 1 / (1 + 10 ** (dr / 400))\n",
    "    actual_score = get_result_score(row['FTR'])\n",
    "    \n",
    "    new_h_elo = h_elo + elo_k * (actual_score - e_prob)\n",
    "    new_a_elo = a_elo + elo_k * ((1 - actual_score) - (1 - e_prob))\n",
    "    \n",
    "    elo_ratings[h_team] = new_h_elo\n",
    "    elo_ratings[a_team] = new_a_elo\n",
    "    \n",
    "    # --- Actualizacion Dixon-Coles (Simplificada) ---\n",
    "    # Basada en Goles Esperados vs Reales\n",
    "    fthg = row['FTHG']\n",
    "    ftag = row['FTAG']\n",
    "    \n",
    "    # Prediccion simple lambda = att * def_rival\n",
    "    # Error = Real - Predicho\n",
    "    # Update Att = Att + lr * Error * Def_Rival\n",
    "    # Update Def = Def + lr * Error * Att_Rival (Defensa inversa a mayor rating mejor? No, usaremos multiplicador directo de goles)\n",
    "    # Nota: Dixon Coles real requiere optimizacion de verosimilitud, aqui usamos un gradiente estocastico simple para adaptarlo partido a partido.\n",
    "    \n",
    "    if not np.isnan(fthg) and not np.isnan(ftag):\n",
    "        pred_hg = h_att * a_def\n",
    "        pred_ag = a_att * h_def\n",
    "        \n",
    "        err_h = fthg - pred_hg\n",
    "        err_a = ftag - pred_ag\n",
    "        \n",
    "        # Actualizar ratings\n",
    "        attack_ratings[h_team] += dc_lr * err_h * a_def\n",
    "        defense_ratings[a_team] += dc_lr * err_h * h_att\n",
    "        \n",
    "        attack_ratings[a_team] += dc_lr * err_a * h_def\n",
    "        defense_ratings[h_team] += dc_lr * err_a * a_att\n",
    "        \n",
    "        # Normalizar para evitar explosion\n",
    "        # (Idealmente mantener medias en 1.0)\n",
    "        \n",
    "\n",
    "df['Home_Elo'] = home_elo_series\n",
    "df['Away_Elo'] = away_elo_series\n",
    "df['Home_Att_Strength'] = home_att_series\n",
    "df['Away_Att_Strength'] = away_att_series\n",
    "df['Home_Def_Weakness'] = home_def_series # Nota: Aqui mas alto significa que CONCEDE mas goles (Weakness)\n",
    "df['Away_Def_Weakness'] = away_def_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09cdaf",
   "metadata": {},
   "source": [
    "## 5. ExportaciÃ³n de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06bf988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Features exportadas a df_final_features.csv con 5700 registros.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = [\n",
    "    'Date', 'Season', 'HomeTeam', 'AwayTeam', 'FTR', 'FTHG', 'FTAG',\n",
    "    'Home_Elo', 'Away_Elo',\n",
    "    'Home_Att_Strength', 'Away_Att_Strength',\n",
    "    'Home_Def_Weakness', 'Away_Def_Weakness',\n",
    "    'Home_FIFA_Ova', 'Away_FIFA_Ova',\n",
    "    'Home_Market_Value', 'Away_Market_Value',\n",
    "    'Home_xG_Avg_L5', 'Away_xG_Avg_L5',          \n",
    "    'Home_Streak_L5', 'Away_Streak_L5',          \n",
    "    'Home_H2H_L3', 'Away_H2H_L3',                \n",
    "    'Home_Pressure_Avg_L5', 'Away_Pressure_Avg_L5',\n",
    "    'B365H', 'B365D', 'B365A'\n",
    "]\n",
    "final_cols = [c for c in feature_cols if c in df.columns]\n",
    "df_final = df[final_cols].copy()\n",
    "df_final.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"âœ… Features exportadas a {OUTPUT_FILE} con {len(df_final)} registros.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2924cfd8-0f9d-4eb6-b609-84aa0ef09226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179672d0-245f-40ac-888a-04fde90cf1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
